{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b89326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image as im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd243a2",
   "metadata": {},
   "source": [
    "##### 0, Define the hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4b874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TODO: change hyper parameters\"\n",
    "n_epochs = 15 #Initially 3. \n",
    "batch_size_train = 64 \n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.1 #Changed manually with different optimization functions\n",
    "momentum = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f27185",
   "metadata": {},
   "source": [
    "##### 1, Loading training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de967eba",
   "metadata": {},
   "source": [
    "#### Organizing images\n",
    "\n",
    "First, we need to create a directory structure to hold our images.\n",
    "The directory <em>training2</em> will hold 10 directories, corresponding to class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660d179-063a-489e-9a3e-5ba78f7eacec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('training2'):\n",
    "    os.mkdir(\"training2\")\n",
    "for i in range(10):\n",
    "    if not os.path.exists(\"training2/{}\".format(i+1)):\n",
    "        os.mkdir(\"training2/{}\".format(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf5a99-0b08-45ca-ae9a-4496cc373f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "file = open(\"labels.txt\",\"r\")\n",
    "for line in file.readlines():\n",
    "    text = line.strip().split(\"\\t\")\n",
    "    shutil.copy(\"training/\" + text[0], \"training2/{0}/\".format(text[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6c015-2a68-49c4-8174-ec30e12bb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),])\n",
    "dataset = datasets.ImageFolder('training2',transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8c4a3",
   "metadata": {},
   "source": [
    "#### 1.2 Now lets load data from torchvision instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ab909",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934fb453",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset0 = datasets.EMNIST('data_set/', download=True, train=True, transform=transform, split='digits')\n",
    "testset0 = datasets.EMNIST('data_set/', download=True, train=False, transform=transform, split='digits')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38b598",
   "metadata": {},
   "source": [
    "##### 1.3 First, check the documentation of dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70088afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset0, batch_size=batch_size_train, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset0, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc34ab73-1341-4a3f-adf2-434c480206bc",
   "metadata": {},
   "source": [
    "1.4 Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e449eb2-5da5-4f0a-9a63-f19f4b1781c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "figure = plt.figure()\n",
    "num_of_images = 60\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcda99c",
   "metadata": {},
   "source": [
    "##### 2 Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce69131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a503bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Read the documentation of torchvision.models to try more cnn models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be229a",
   "metadata": {},
   "source": [
    "##### 3 Write the training function and the testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b55b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    # evaluation, freeze \n",
    "    model.eval()\n",
    "    total_num = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for _, (data, target) in enumerate(test_loader):\n",
    "            \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            predict_one_hot = model(data)\n",
    "            \n",
    "            _, predict_label = torch.max(predict_one_hot, 1)\n",
    "            \n",
    "            total_correct += (predict_label == target).sum().item()\n",
    "            total_num += target.size(0)\n",
    "        \n",
    "    return (total_correct / total_num)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681307a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, num_epoch, learning_rate, momentum, device):\n",
    "    train_losses = []\n",
    "    \n",
    "    # 1, define optimizer\n",
    "    \n",
    "    \"TODO: try different optimizer\"\n",
    "    \n",
    "    \n",
    "    #optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "    #                  momentum=momentum)\n",
    "    \n",
    "    #The Adam algorithm should be more expensive to train, but may result in a higher accuracy\n",
    "    optimizer = optim.Adam(network.parameters()) #Using default learning rate of 1e-3\n",
    "    #optimizer = optim.AdamW(network.parameters())\n",
    "    \n",
    "    for epoch in tqdm(range(num_epoch)):\n",
    "        # train the model\n",
    "        model.train()\n",
    "        \n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 2, forward\n",
    "            output = network(data)\n",
    "            \n",
    "            \n",
    "            # 3, calculate the loss\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \"TODO: try use cross entropy loss instead \"\n",
    "            \n",
    "            \n",
    "            #loss = F.nll_loss(output, target)\n",
    "            \n",
    "            loss = F.cross_entropy(output, target)\n",
    "            \n",
    "            # 4, backward\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "        # evaluate the accuracy on test data for each epoch\n",
    "        accuracy = test(model, test_loader, device)\n",
    "        print('accuracy', accuracy)\n",
    "        \n",
    "    # 5, save model\n",
    "    \n",
    "    \"TODO: change the number of epochs save the model with the best prediction accuracy\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e854b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device0 = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# use cpu if you do not have gpu installed in your computer\n",
    "network = Net().to(device0)\n",
    "train(model=network, train_loader=trainloader, test_loader=testloader, num_epoch=n_epochs, learning_rate=learning_rate, momentum=momentum, device=device0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a06b3d0",
   "metadata": {},
   "source": [
    "#### 4 Calculate the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f49b2c-40da-41ba-a489-7add5a8cdf40",
   "metadata": {},
   "source": [
    "0.98625 accuracy using the provided optimizer (SGD), loss function (SGD), and epochs (3).\n",
    "\n",
    "0.9895 accuracy using Adam optimization algorithm, cross entropy loss function, and 3 epcohs.\n",
    "\n",
    "0.99005 accuracy using Adam optimization algorithm, cross entropy loss function, and 5 epochs.\n",
    "\n",
    "0.98985 accuracy using AdamW optimization algorithm, cross entropy loss function, and 5 epochs.\n",
    "\n",
    "0.991325 accuracy using Adam optimization algorithm, cross entropy, and 15 epochs. \n",
    "\n",
    "Increasing the number of epochs increased the accuracy overall.\n",
    "\n",
    "The Adam or AdamW optimization algorithms seem to be the most accurate than SGD.\n",
    "\n",
    "I am running this on a virtual machine with 3gb of RAM, 1 cpu core, and no gpu, so training this takes a very long time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8286f-8c00-4d3d-935f-a5cee15544ba",
   "metadata": {},
   "source": [
    "### Saving the model trained with Adam, cross entropy, 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73265995-1c5e-45fe-9861-4d1e68e79a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network, './MNIST_model.pt') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c76556-51f4-456e-9145-0527a1dd651a",
   "metadata": {},
   "source": [
    "# 5 - Using a model without convolution\n",
    "\n",
    "Of course, a CNN is better suited for image recognition, but I want to compare it to a sequential model without convolution to see how it performs.\n",
    "\n",
    "Source: https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd622986-8cf3-439b-8f23-1a9df1e8ea09",
   "metadata": {},
   "source": [
    "### Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d0bf8-6ddb-40da-84f6-2f24bf06a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 #28*28 pixels\n",
    "hidden_sizes = [128, 64] #128 neurons in first hidden layer, 64 in second\n",
    "output_size = 10 #10 digits, 10 outputs\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(), \n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda06f1f-c02b-48c9-9970-748f6c8f5596",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d636835-ca56-420a-b135-e871aa0ba26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() #nll loss function, same as initial above\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images) #log probabilities\n",
    "loss = criterion(logps, labels) #calculate the NLL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b0d274-adc4-4f8e-b790-c39e2d71eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9) #SGD optimizer, same as the initial optimizer above\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        #This is where the model learns by backpropagating\n",
    "        loss.backward()\n",
    "        \n",
    "        #And optimizes its weights here\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2347c5-f290-4a8c-a8dd-85d7a112d753",
   "metadata": {},
   "source": [
    "### Testing this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a6f01-883a-400b-ab88-75789339f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count, all_count = 0, 0\n",
    "for images,labels in testloader:\n",
    "  for i in range(len(labels)):\n",
    "    img = images[i].view(1, 784)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "\n",
    "    \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    true_label = labels.numpy()[i]\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb0ec0-7808-4723-98b5-6b6222149616",
   "metadata": {},
   "source": [
    "0.984125 accuracy with 5 epochs, SGD optimization, and nll loss function.\n",
    "\n",
    "Using the same optimization algorithm and loss function above in the CNN, we achieved 0.98625 accuracy in just 3 epochs.\n",
    "\n",
    "CNN therefore appears better suited to image recognition, although using this model is not far off. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11800328-5151-4918-8a6a-ec49884ba15d",
   "metadata": {},
   "source": [
    "# In Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15a6c0-471b-4263-b499-8bea4431d92a",
   "metadata": {},
   "source": [
    "For the CNN, the Adam algorithm works better than the SGD.\n",
    "\n",
    "Cross entropy worked better than nll as a loss function.\n",
    "\n",
    "More epochs are better. I tested 3, 5, and 15. \n",
    "\n",
    "After 5 epochs, the accuracy went down slightly before rising again. \n",
    "\n",
    "Using convolution, we can achieve higher image classification accuracy.\n",
    "\n",
    "\n",
    "Overall, I felt that I was limited by the performance of my computer. As mentioned above, I am running this on a virtual machine with 3gb RAM, 1 CPU core, and no CUDA/GPU. I imagine that if I had a better computer, I could more easily test different hyper-parameters and increase the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc36d7-1fcc-4acf-895c-5b4edc14278b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
